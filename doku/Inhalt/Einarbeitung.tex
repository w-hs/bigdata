\section{Einarbeitung}
In der Einarbeitungsphase haben wir uns zunächst für eine Hadoop-Arbeitsumgebung entschieden. Da die meisten Projektteilnehmer über lediglich vier Gigabyte Arbeitsspeicher verfügen, fiel unsere Wahl auf die ressourcenschonende Hortonworks Sandbox\footnote{\url{http://hortonworks.com/products/hortonworks-sandbox/}}, die bei allen Teilnehmern problemlos ausgeführt werden konnte. Unter Verwendung der Sandbox haben wir den Umgang mit dem Hadoop-Ecosystem gelernt und erste Map/Reduce-Jobs ausgeführt. Darüber hinaus konnten wir weitere Tools wie Hive und Pig verwenden.

\renewcommand{\arraystretch}{1.3}

\subsection{Datenmodell}
Abbildung \ref{fig:ShoppersTables} zeigt das Datenmodell, dass aus den Entitäten "`transactions"', "`history"', "'offers"', und "`submissions"' besteht. 

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{Bilder/ShoppersTables}
\caption{Das Datenmodell der Shoppers-Challenge}
\label{fig:ShoppersTables}
\end{figure}

In den "`transactions"' (s. Tabelle \ref{tab:transactions}) stehen die Einkäufe der Kunden.
Die "`offers"' (s. Tabelle \ref{tab:offers}) enthalten Gutscheine, die an den Kunden verteilt wurden.
In der "`train\_history"' (s. Tabelle \ref{tab:trainhistory}) sind Informationen über die angebotenen Coupons enthalten.
Die "`test\_history"' entspricht der "`train\_history"' mit dem Unterschied, dass die beiden Felder "`repeattrips"' und "`repeater"' fehlen. Diese sind absichtlich nicht enthalten, da eine Vorhersage über diese Werte getroffen werden soll.
Die "`submissions"' (s. Tabelle \ref{tab:submissions}) enthalten die Ergebnisse, die wir bei Kaggle einreichen. Dabei wird einem Kunden eine Wiederkaufswahrscheinlichkeit zugeordnet.

Ziel dieses Projekts ist es, die Daten aus den "`transactions"', "`offers"' sowie der beiden Historiendaten zur Generierung von "`submissions"' zu nutzen. Es sollen Vorhersagen für alle Kunden-IDs aus der "`test\_history"' gemacht werden.

\begin{table}[h]
\centering
\begin{tabular}{l|l}
	 \textbf{Feld} & \textbf{Bedeutung}  \\ 
	\hline id & ID des Kunden \\ 
	\hline chain & ID der Marktkette \\ 
	\hline dept  & ID der Produktoberkategorie (z.B. Elektronikgeräte)  \\ 
	\hline category & ID der Produktkategorie (z.B. Smartphones) \\ 
	\hline company & ID der Firma die das Produkt verkauft \\ 
	\hline brand & ID der Marke (z.B. iPhone) \\ 
	\hline date & Kaufdatum \\
	\hline productsize & Menge die gekauft wurde (2L Wasser, 500g Mehl) \\ 	
	\hline productmeasure & Einheit (Liter, Gramm, Stück) \\ 	
	\hline purchasequantity & Stückzahl die gekauft wurde (Drei 2L Flaschen Wasser)
	\vspace{0.3cm} \\ 
\end{tabular}
\caption{transactions}
\label{tab:transactions}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{l|l}
	\textbf{Feld} & \textbf{Bedeutung}  \\ 
	\hline offer & ID des Coupon \\ 
	\hline category & ID der Produktkategorie \\ 
	\hline quantity & Stückzahl ab der ein Coupon gilt \\ 
	\hline company & ID der Firma die Coupons anbietet \\ 
	\hline offervalue & Preis \\ 
	\hline brand & ID der Marke
	\vspace{0.3cm} \\ 
\end{tabular}
\caption{offers}
\label{tab:offers}
\end{table}

\begin{table}[h]
\centering
\begin{tabular}{l|l}
	\textbf{Feld} & \textbf{Bedeutung}  \\ 
	\hline id & ID des Kunden \\ 
	\hline chain & ID der Marktkette \\ 
	\hline offer  & ID des Coupon  \\ 
	\hline market & ID der Region in der sich der Markt befindet  \\ 
	\hline repeattrips & Anzahl der Wiederholungskäufe (gleiches Produkt)  \\ 
	\hline repeater & Gibt an, ob repeattrips größer 0 ist \\ 
	\hline offerdate & Datum an dem der Kunde den Coupon erhalten hat 
	\vspace{0.3cm} \\ 
\end{tabular} 
\caption{train\_history}
\label{tab:trainhistory}
\end{table}

\begin{table}[h]
	\centering
\begin{tabular}{l|l}
	\textbf{Feld} & \textbf{Bedeutung}  \\ 
	\hline id & ID des Kunden \\ 
	\hline repeatProbability & Wahrscheinlichkeit das der Kunde erneut kauft 
	\vspace{0.3cm} \\
\end{tabular} 
\caption{submissions}
\label{tab:submissions}
\end{table}

\subsection{Technologieentscheidung}
Zu Beginn des Projekts haben wir uns Gedanken über die Auswahl der Technologien gemacht. Zum Zeitpunkt der Einarbeitungsphase haben wir bereits Hive und Pig durch gruppenübergreifende Vorträge kennen gelernt. Darüber hinaus standen uns keine weiteren Optionen zur Verfügung, da alternative Technologien erst zu einem späteren Zeitpunkt vorgestellt worden sind.

Somit beschränkte sich die Technologieentscheidung auf die Wahl zwischen Hive und Pig. Da wir in unserem Projekt ausschließlich Analysen auf strukturierte Daten durchgeführt haben, fiel unsere Entscheidung auf Hive. Der einfache Datenimport in Form von Tabellen und die einfachen Abfragemöglichkeiten in der SQL-ähnlichen Abfragesprache HQL waren die ausschlaggebenden Kriterien.

Die Technologien, die wir neben Hive verwendet haben, werden im weiteren Verlauf der Dokumentation erläutert.


\subsection{Data-Mining-Verfahren}
In diesem Kapitel werden wir einen Überblick über Data-Mining-Verfahren geben, die wir im Verlauf dieses Projekts eingesetzt haben. Nach einer Erläuterung des grundlegenden Prinzips des Machine Learning werden zwei Daten-Mining-Konzepte, Regressionsanalyse und Klassifizierung, vorgestellt. Im Anschluss werden mögliche Werkzeuge zum Machine Learning erläutert.

\subsubsection{Machine Learning}
\label{subsubSec:MachineLearning}
Auf Wikipedia\footnote{\url{https://de.wikipedia.org/wiki/Maschinelles_Lernen}} wird Machine Learning wie folgt beschrieben: 

\begin{center}
“Maschinelles Lernen ist ein Oberbegriff für die 'künstliche' Generierung von Wissen aus Erfahrung: Ein künstliches System lernt aus Beispielen und kann nach Beendigung der Lernphase verallgemeinern.”
\end{center}

Beim Machine Learning wird versucht aus vorhanden Informationen ein Modell zu generieren, welches eingesetzt werden kann, um eine Aussage über neu hinzukommende Informationen zu treffen. Erstere Informationen, die zur Erstellung des Modells genutzt werden, sind die sogenannten Trainingsdaten. Letztere Informationen, über die eine Aussage getroffen werden soll, nennt man Testdaten.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{Bilder/DataMining}
\caption{Machine Learning im Modell}
\label{fig:MachineLearning}
\end{figure}

In unserem Fall des Kaggle-Projekts setzen sich die Trainingsdaten aus den Tabellen \textit{offers, transactions} und \textit{trainHistory} zusammen. Die Testdaten liegen in der Tabelle \textit{testHistory}. Das zu erzeugende Modell soll eine Aussage darüber treffen, ob ein Kunde erneut kaufen wird.

Es gibt 3 Kategorien beim Machine Learning.

\begin{description}
\item[Bestärkendes Lernen] Das bestärkende Lernen (engl. reinforcement learning) ist das Lernen durch Belohnung und Bestrafung. Wir werden hier aber nicht weiter auf das bestärkende Lernen eingehen.

\item [Überwachtes Lernen] Beim überwachtem Lernen (engl. supervised learning) übergibt man einem Algorithmus Paare aus Eingabedaten und Funktionswerten. Dieser erstellt daraus ein Modell, das zu einer neuen Eingabe eine Aussage über den Funktionswert trifft. Beispiele für das überwachte Lernen sind Regressionsanalyse und Klassifizierung.

\item[Unüberwachtes Lernen] Beim unüberwachtem Lernen (engl. unsupervised learning) erzeugt ein Algorithmus ein Modell unter Betrachtung einer Menge von Eingabedaten. Dieses Modell soll eine Aussage über die Eingabedaten treffen. Das typische Beispiel für unüberwachtes Lernen ist Clustering. Hierbei wird versucht Gruppen in der Menge der Eingabedaten ausfindig zu machen.
\end{description}
 
Im Rahmen dieses Projekts werden wir uns vorrangig mit dem überwachten Lernen beschäftigen. Denkbar sind zum einen eine Regressionsanalyse und zum anderen eine binäre Klassifizierung. Für dieses Projekt kann man sich eine Regressionsanalyse vereinfacht so vorstellen, dass man eine Menge von Eingabedaten hat und eine Funktion findet, die dafür einen Funktionswert zwischen 0 bis 1 generiert. Dieser Wert stellt die Wahrscheinlichkeit dar, dass ein Kunde erneut kauft. Der Nachteil liegt darin, dass die Funktionswerte  bei den Trainingsdaten nur 0 oder 1 sind und keinen Wert dazwischen einnehmen. Dies führt uns zu einem binären Ansatz im Sinne der binären Klassifizierung. Die beiden möglichen Klassen sind hierbei 0 und 1. 0 für 'Kunde kauft nicht erneut' und 1 für 'Kunde kauft erneut'. Der Algorithmus soll eine Aussage treffen zu welcher Wahrscheinlichkeit ein Testdatensatz zur Klasse 0 oder 1 gehört.

Bei der Regressionsanalyse und Klassifizierung gibt es das Problem der Überanpassung (engl. overfitting). Von Overfitting spricht man, wenn ein Algorithmus die Trainingsdaten 'auswendig' gelernt und keine Funktion erstellt hat, die die Verbindungen in den Datensätzen darstellt. Zur Verhinderung von Overfitting übergibt man nur die wichtigen bzw. relevanten Daten an den Algorithmus zur Erstellung des Modells. Diese Einschränkung der Daten nennt man 'feature selection'.

\subsubsection{Online/Offline Machine Learning}

Beim Machine Learning gibt es zu den vorgestellten Kategorien noch zwei Oberkategorien, zum einen das Online Machine Learning und zum anderen das Offline Machine Learning. Beim Online Machine Learning nimmt der Algorithmus schrittweise je einen Datensatz aus den Trainingsdaten und passt daraufhin das Modell an. Daher kann beim Online Machine Learning das Modell erweitert werden. Dies ist zum Beispiel dann von Vorteil wenn man ein Modell über Trainingsdaten der letzten Jahre hat und dieses um die Daten der vergangenen Tage erweitern will. Der Nachteil ist allerdings, dass die Reihenfolge, in der die Trainingsdaten eingelesen werden, Einfluss auf das Modell haben. Im Gegensatz dazu können beim Offline Machine Learning nur einmal Trainingsdaten übergeben werden. Diese werden unabhängig von der Reihenfolge verarbeitet.

\begin{table}[H]
	\centering
\begin{tabular}{l|c|c} 
	\textbf{} & \textbf{Offline learning} & \textbf{Online learning}  \\  
	\hline \textbf{Reihenfolge entscheidend} & nein & ja \\
	\hline \textbf{Modell erweiterbar} & nein & ja 
	\vspace{0.3cm} 
\end{tabular} 
\caption{Trainingsdaten beim Machine learning}
\label{tab:MachineLearningTrainingData}
\end{table}
 
\subsubsection{Werkzeuge}
In diesem Kapitel stellen wir mögliche Werkzeuge für Machine Learning vor, die für dieses Projekt in Frage kommen.

\begin{description}
\item[Vowpal Wabbit] Vowpal Wabbit ist ein Open-Source Programm für Online Machine Learning. Es wurde ursprünglich bei Yahoo! Research entwickelt und wird heute von Microsoft Research unterhalten. Es bietet die Möglichkeit Klassifizierungs- und Regressionsalgorithmen zu verwenden.

\item[Mahout] Apache Mahout ist eine Projekt zur Implementierung von Machine Learning, das in erster Linie auf Collaborative Filtering, Clustering und Klassifikation fokussiert ist. Die bekanntesten Implementierungen von Mahout setzen auf Hadoop auf und nutzen das Map/Reduce-Verfahren. Eine Einbindung von Mahout in AWS ist relativ einfach zu bewerkstelligen.

\item[Glmnet] Glmnet ist ein R-Package das lineare und logistische Regression implementiert.
\end{description}

Die Tabelle \ref{tab:MachineLearningTools} stellt die möglichen Anwendungsumgebungen der Implementierungen dar.

\begin{table}[H]
	\centering
\begin{tabular}{l|c|c|c} 
	\textbf{} & \textbf{HDFS (HortonWorks)} & \textbf{AWS} & \textbf{Lokal}  \\  
	\hline \textbf{Vowpal Wabbit} & - & - & x \\
	\hline \textbf{Apache Mahout} & x & x & x \\
	\hline \textbf{Glmnet} & x & x & x 
	\vspace{0.3cm} 
\end{tabular} 
\caption{Anwendungsumgebungen der Machine Learning Werkzeuge}
\label{tab:MachineLearningTools}
\end{table}

