\section{Schlussteil}

\subsection{Ausblick}
Es konnte bereits während des Projektes ein gutes Ergebnis erzielt
werden. Dennoch wurden aufgrund der knappen Zeit nicht alle Ideen
umgesetzt. Weitere Möglichkeiten sehen wir im Bereich der nicht
verwendeten Daten und der Nutzung eines Offline-Learning-Verfahrens.
Des Weiteren besteht die Möglichkeit, die verwendeten Features auf ihre
Aussagekraft beziehungsweise Qualität zu untersuchen.

\subsubsection{Verwendung aller Daten}
Es werden bisher hauptsächlich Transaktionen berücksichtigt, die in Beziehung zu Gutscheinen stehen.
Bei diesen Transaktionen muss die Marke, die Kategorie oder das Unternehmen mit dem entsprechenden Gutschein übereinstimmen.
Diese Daten könnten in einem nächsten Iterationsschritt ebenfalls verwertet werden, wozu zunächst die folgenden Ansätze zusammengetragen wurden:
	
\begin{itemize}
\item Für jeden Kunden soll der komplette Umsatz pro Quartal bzw. pro Jahr ermittelt werden. Die Idee ist, dass Kunden, die viel Geld umsetzen, weniger gut durch Gutscheine ansprechbar sind, als die Kunden, die wenig zum Umsatz beitragen. 
 
\item Kunden, die in regelmäßigen Abständen einkaufen, kommen sehr wahrscheinlich wieder.
Beispielsweise werden wöchentlich die Nahrungsvorräte auf dem Heimweg von der Arbeit aufgefüllt.
Die Frequenz des Einkaufens kann über die Auswertung der Zeitangaben der Transaktionen ermittelt werden.

\item Clustering von oft zusammen gekauften Marken, Kategorien und Unternehmen. Auf dieser Basis können Features für die Kunden definiert werden.
	
\item Kunden, die große Mengen gekauft haben, kommen wahrscheinlich wieder. Sie benötigen allerdings keine Gutscheine, da der Preis für sie bereits in Ordnung ist oder der Markt beispielsweise zum Einkauf gut gelegen ist. Für eine Umsetzung gilt es eine Definition für "große Menge" zu finden.  Denkbar wäre große Menge als überdurchschnittlich zu definieren, was sich einfach implementieren ließe.
\end{itemize}

\subsubsection{Bewertung von Features}	
Sowohl bei den verwendeten Features als auch bei den oben vorgestellten Ideen ist bisher unklar, inwiefern diese Features das Kaufverhalten positiv, negativ oder überhaupt beeinflussen.
In unseren Vorträge zur Veranstaltung ist zur Sprache gekommen, dass statistische Auswertungsverfahren zur Verfügung stehen, welche Aufschluss über die Qualität der Features treffen können. Da schlechte Features das Ergebnis negativ verfälschen können, ist dieser Ansatz besonders interessant.
Zur Umsetzung müsste die Korrelation zwischen den einzelnen Features und dem Wiederkaufverhalten gemessen werden. Auf dieser Basis kann ein Grenzwert festgelegt werden, ab dem ein Feature
zur Voraussage genutzt wird.

\subsubsection{Offline Learning Verfahren}	
	

\subsection{Fazit}
Im Allgemeinen verschafften die Veranstaltung und das Projekt einen guten Gesamtüberblick über das Themengebiet Big-Data. Für uns alle war dieses Themengebiet unbekannt und es musste initial viel Aufwand in das Grundverständnis investiert werden. Die begleitenden Vorträge waren dabei sehr hilfreich und passten sehr gut zu dem von uns gewählten Iterativen Ansatz. Wurde innerhalb eines Vortrages eine neue und für unser Projekt passende Technologie vorgestellt, konnten wir diese direkt in der nächsten Iteration nutzen.
Angemerkt sei jedoch, dass durch die Masse der Vorträge entsprechend viele Technologien präsentiert wurden, die sich nicht alle für unser Projekt nutzen ließen. Dies hinterlässt das Gefühl alles gehört zu haben, jedoch nur wenige Technologien wirklich zu kennen.
Positiv aufgefallen die Arbeit mit dem Amazon-Webservice. Bei den Webservices können wir in der Cloud bei Amazon direkt Jobs auf großen Datenmengen ausführen, was mit unseren normalen Maschinen nicht möglich gewesen wäre. Diese Möglichkeit wird auch von vielen Unternehmen genutzt, sodass ein Einblick in Praxis für uns sehr interessant war. Durch unsere Nachlässigkeit wurde auch das von Amazon gesponsorte Kapital dezimiert, nachdem vergessen wurde den Cluster zu terminieren - und damit wirkliches Geld verloren ist.

Insgesamt konnten wir durch den Einsatz immer neuer Technologien wie MapReduce oder Hive und Verfahren ein deutlich besseres Ergebnis als die Gruppe im Vorjahr erreichen. Den Fortschritt über die Iterationen zeigt das folgende Diagramm.

[TollesDiagramm]

Wie im Diagramm zu sehen, erreichten wir in Iteration 5 mit Platz 241 unsere bisher beste Platzierung und überholten mit diesem Ergebnis auch die Gruppe des Vorjahres, die Platz 452 erreichte. 

Generell gab die Veranstaltung einen guten Einstieg in die Verarbeitung großer Datenmengen und die dafür nötigen Werkzeuge. Es bleibt die Erkenntnis das es ein sehr umfassendes Gebiet ist, so dass für ein erfolgreiches Arbeiten in dem Bereich mehr als eine Veranstaltung nötig ist um einen wirklichen Einstieg zu schaffen.